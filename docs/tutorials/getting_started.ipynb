{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with HySplit\n",
    "\n",
    "**hysplit** is a Python package for conducting trajectory and dispersion modeling with HYSPLIT (HYbrid Single-Particle Lagrangian Integrated Trajectory). This is a Python port of the R [splitr](https://github.com/rich-iannone/splitr) package.\n",
    "\n",
    "This tutorial covers:\n",
    "1. Installation\n",
    "2. Trajectory modeling\n",
    "3. Dispersion modeling\n",
    "4. Cluster computing workflows (download + run phases)\n",
    "5. Batch processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installation\n",
    "\n",
    "Install from PyPI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic installation\n",
    "!pip install hysplit\n",
    "\n",
    "# With visualization support\n",
    "# !pip install \"hysplit[viz]\"\n",
    "\n",
    "# With all optional dependencies\n",
    "# !pip install \"hysplit[all]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Trajectory Modeling\n",
    "\n",
    "Trajectory models track the path of air masses moving forward or backward in time. This is useful for:\n",
    "- Determining where air at a location came from (backward trajectory)\n",
    "- Predicting where air from a source will go (forward trajectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hysplit\n",
    "from datetime import datetime\n",
    "\n",
    "print(f\"hysplit version: {hysplit.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Simple Trajectory Run\n",
    "\n",
    "Run a 24-hour forward trajectory from Ontario, Canada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run trajectory model\n",
    "trajectory = hysplit.hysplit_trajectory(\n",
    "    lat=42.83752,              # Latitude (Ontario, Canada)\n",
    "    lon=-80.30364,             # Longitude\n",
    "    height=50,                 # Height above ground (meters)\n",
    "    duration=24,               # Duration in hours\n",
    "    days=[\"2012-03-12\"],       # Date(s) to run\n",
    "    daily_hours=[0, 6, 12, 18], # Hours to run each day\n",
    "    direction=\"forward\",       # Direction: \"forward\" or \"backward\"\n",
    "    met_type=\"reanalysis\",     # Meteorological data type\n",
    "    extended_met=False,        # Include extended meteorology\n",
    "    met_dir=\"./met\",           # Directory for met files\n",
    "    exec_dir=\"./out\"           # Directory for output\n",
    ")\n",
    "\n",
    "print(f\"Trajectory shape: {trajectory.shape}\")\n",
    "trajectory.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Understanding the Output\n",
    "\n",
    "The trajectory DataFrame contains:\n",
    "\n",
    "| Column | Description |\n",
    "|--------|-------------|\n",
    "| `run` | Index for individual model run |\n",
    "| `receptor` | Numeric label for the 3D receptor position |\n",
    "| `hour_along` | Hours from start (positive=forward, negative=backward) |\n",
    "| `traj_dt` | Date-time of trajectory position |\n",
    "| `lat`, `lon`, `height` | Position along trajectory |\n",
    "| `pressure` | Air pressure (hPa) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "print(\"Trajectory Summary:\")\n",
    "print(f\"  Number of runs: {trajectory['run'].nunique()}\")\n",
    "print(f\"  Lat range: {trajectory['lat'].min():.4f} - {trajectory['lat'].max():.4f}\")\n",
    "print(f\"  Lon range: {trajectory['lon'].min():.4f} - {trajectory['lon'].max():.4f}\")\n",
    "print(f\"  Height range: {trajectory['height'].min():.1f} - {trajectory['height'].max():.1f} m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Method Chaining (Pipeline) API\n",
    "\n",
    "For more complex workflows, use the object-oriented pipeline approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model using method chaining\n",
    "trajectory_model = (\n",
    "    hysplit.create_trajectory_model()\n",
    "    .add_trajectory_params(\n",
    "        lat=43.45,\n",
    "        lon=-79.70,\n",
    "        height=50,\n",
    "        duration=6,\n",
    "        days=[\"2015-07-01\"],\n",
    "        daily_hours=[0, 12],\n",
    "        direction=\"backward\",\n",
    "        met_type=\"reanalysis\",\n",
    "        met_dir=\"./met\",\n",
    "        exec_dir=\"./out\"\n",
    "    )\n",
    "    .run()\n",
    ")\n",
    "\n",
    "# Extract the trajectory data\n",
    "trajectory_df = trajectory_model.get_output_tbl()\n",
    "trajectory_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Plotting Trajectories\n",
    "\n",
    "Visualize trajectories on an interactive map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot trajectory on interactive map\n",
    "hysplit.trajectory_plot(trajectory_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Extended Meteorology\n",
    "\n",
    "Get additional meteorological variables along the trajectory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run with extended meteorology\n",
    "trajectory_ext = hysplit.hysplit_trajectory(\n",
    "    lat=42.83752,\n",
    "    lon=-80.30364,\n",
    "    height=50,\n",
    "    duration=24,\n",
    "    days=[\"2012-03-12\"],\n",
    "    daily_hours=[12],\n",
    "    direction=\"forward\",\n",
    "    met_type=\"reanalysis\",\n",
    "    extended_met=True,  # Enable extended meteorology\n",
    "    met_dir=\"./met\",\n",
    "    exec_dir=\"./out\"\n",
    ")\n",
    "\n",
    "# Extended columns include:\n",
    "# theta, air_temp, rainfall, mixdepth, rh, sp_humidity, h2o_mixrate, terr_msl, sun_flux\n",
    "print(f\"Columns with extended_met=True: {list(trajectory_ext.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dispersion Modeling\n",
    "\n",
    "Dispersion models simulate the transport and spread of particles or gases from emission sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "start_time = datetime(2015, 7, 1, 0, 0)\n",
    "\n",
    "# Create dispersion model\n",
    "dispersion_model = (\n",
    "    hysplit.create_dispersion_model()\n",
    "    .add_source(\n",
    "        name=\"particle\",\n",
    "        lat=49.0,                    # Vancouver, Canada\n",
    "        lon=-123.0,\n",
    "        height=50,                   # Emission height (m)\n",
    "        rate=5,                      # Emission rate (mass units/hour)\n",
    "        pdiam=15,                    # Particle diameter (micrometers)\n",
    "        density=1.5,                 # Particle density (g/cm³)\n",
    "        shape_factor=0.8,            # Shape factor (0-1)\n",
    "        release_start=start_time,\n",
    "        release_end=start_time + timedelta(hours=2)\n",
    "    )\n",
    "    .add_dispersion_params(\n",
    "        start_time=start_time,\n",
    "        end_time=start_time + timedelta(hours=6),\n",
    "        direction=\"forward\",\n",
    "        met_type=\"reanalysis\",\n",
    "        met_dir=\"./met\",\n",
    "        exec_dir=\"./out\"\n",
    "    )\n",
    "    .run()\n",
    ")\n",
    "\n",
    "# Get dispersion output\n",
    "dispersion_df = dispersion_model.get_output_tbl()\n",
    "print(f\"Dispersion shape: {dispersion_df.shape}\")\n",
    "dispersion_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Plotting Dispersion Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot particle positions\n",
    "dispersion_model.dispersion_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Cluster Computing Workflows\n",
    "\n",
    "For HPC environments without internet access, use the two-phase workflow:\n",
    "\n",
    "1. **Download phase**: Download meteorological data on a machine with internet\n",
    "2. **Run phase**: Execute models on the cluster using pre-downloaded data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Phase 1: Download Meteorological Data\n",
    "\n",
    "Run this on a machine with internet access:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hysplit.workflows import download_met_data, create_met_manifest\n",
    "\n",
    "# Download all needed meteorological files for a date range\n",
    "manifest = download_met_data(\n",
    "    met_type=\"reanalysis\",\n",
    "    start_date=\"2012-03-01\",\n",
    "    end_date=\"2012-03-31\",\n",
    "    output_dir=\"/data/met/reanalysis\",\n",
    "    buffer_days=2,             # Extra days for boundary conditions\n",
    "    compute_checksums=True,    # For data validation\n",
    "    n_workers=4                # Parallel downloads\n",
    ")\n",
    "\n",
    "print(f\"Downloaded {len(manifest['files'])} files\")\n",
    "print(f\"Total size: {manifest['total_size_mb']:.1f} MB\")\n",
    "\n",
    "# Save manifest for transfer to cluster\n",
    "create_met_manifest(manifest, \"/data/met/manifest.json\")\n",
    "print(\"Manifest saved to /data/met/manifest.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Phase 2: Run Models Offline\n",
    "\n",
    "Run this on the cluster (no internet required):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hysplit.workflows import run_trajectory_offline, load_met_manifest\n",
    "\n",
    "# Load pre-downloaded manifest\n",
    "manifest = load_met_manifest(\"/scratch/met/manifest.json\")\n",
    "\n",
    "# Validate data integrity (optional but recommended)\n",
    "from hysplit.workflows import validate_met_data\n",
    "validation = validate_met_data(\"/scratch/met/manifest.json\", check_checksums=True)\n",
    "print(f\"Validation: {validation['status']}\")\n",
    "\n",
    "# Run trajectory without internet\n",
    "trajectory = run_trajectory_offline(\n",
    "    lat=42.83752,\n",
    "    lon=-80.30364,\n",
    "    height=50,\n",
    "    duration=24,\n",
    "    days=[\"2012-03-12\"],\n",
    "    met_manifest=manifest,\n",
    "    exec_dir=\"/scratch/output\"\n",
    ")\n",
    "\n",
    "trajectory.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Batch Processing\n",
    "\n",
    "Run many trajectories in parallel for maximum performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hysplit.workflows import create_batch_config, run_batch_trajectories\n",
    "\n",
    "# Define batch configuration\n",
    "config = create_batch_config(\n",
    "    locations=[\n",
    "        {\"lat\": 42.83752, \"lon\": -80.30364},  # Ontario\n",
    "        {\"lat\": 43.65107, \"lon\": -79.34702},  # Toronto\n",
    "        {\"lat\": 45.50169, \"lon\": -73.56725},  # Montreal\n",
    "        {\"lat\": 49.28273, \"lon\": -123.12074}, # Vancouver\n",
    "        {\"lat\": 51.04532, \"lon\": -114.05719}, # Calgary\n",
    "    ],\n",
    "    days=[\"2012-03-10\", \"2012-03-11\", \"2012-03-12\"],\n",
    "    daily_hours=[0, 6, 12, 18],\n",
    "    duration=48,\n",
    "    met_dir=\"/data/met\",\n",
    "    exec_dir=\"/scratch/output\"\n",
    ")\n",
    "\n",
    "print(f\"Batch configuration:\")\n",
    "print(f\"  Total runs: {config.total_runs}\")\n",
    "print(f\"  Locations: {len(config.locations)}\")\n",
    "print(f\"  Days: {len(config.days)}\")\n",
    "print(f\"  Hours per day: {len(config.daily_hours)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run with 8 parallel workers\n",
    "results = run_batch_trajectories(config, n_workers=8)\n",
    "\n",
    "print(f\"Completed {len(results)} trajectory runs\")\n",
    "print(f\"Total rows: {sum(len(df) for df in results.values())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 SLURM Job Array Generation\n",
    "\n",
    "For cluster environments with SLURM, generate job array scripts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate SLURM job array script\n",
    "slurm_script = config.to_slurm_array(\n",
    "    script_path=\"run_trajectories.sh\",\n",
    "    python_script=\"run_single_trajectory.py\",\n",
    "    partition=\"compute\",\n",
    "    time=\"01:00:00\",\n",
    "    memory=\"4G\"\n",
    ")\n",
    "\n",
    "print(\"SLURM script generated:\")\n",
    "print(slurm_script[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Meteorological Data Types\n",
    "\n",
    "Available meteorological data sources:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "met_types = pd.DataFrame({\n",
    "    \"Type\": [\"gdas1\", \"gdas0p5\", \"reanalysis\", \"narr\", \"nam12\", \"gfs0p25\", \"era5\"],\n",
    "    \"Description\": [\n",
    "        \"GDAS 1-degree\",\n",
    "        \"GDAS 0.5-degree\",\n",
    "        \"NCEP/NCAR Reanalysis\",\n",
    "        \"North American Regional Reanalysis\",\n",
    "        \"NAM 12 km\",\n",
    "        \"GFS 0.25-degree\",\n",
    "        \"ERA5 Reanalysis\"\n",
    "    ],\n",
    "    \"Resolution\": [\"1°\", \"0.5°\", \"2.5°\", \"32 km\", \"12 km\", \"0.25°\", \"0.25°\"],\n",
    "    \"Coverage\": [\"Global\", \"Global\", \"Global\", \"N. America\", \"N. America\", \"Global\", \"Global\"]\n",
    "})\n",
    "\n",
    "met_types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Configuration Options\n",
    "\n",
    "Customize HYSPLIT parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom configuration\n",
    "config = hysplit.set_config(\n",
    "    numpar=5000,       # Number of particles\n",
    "    maxpar=20000,      # Maximum particles\n",
    "    tratio=0.75,       # Time step ratio\n",
    "    delt=0.0,          # Integration time step (0=auto)\n",
    "    mgmin=10,          # Minimum mixing depth\n",
    "    kmixd=0,           # Mixing depth option\n",
    "    kmix0=250,         # Minimum mixing depth for unstable\n",
    "    kzmix=0,           # Vertical mixing option\n",
    "    kdef=0,            # Deformation option\n",
    "    kbls=1,            # Boundary layer scheme\n",
    "    kblt=2,            # Turbulence option\n",
    "    extended_met=True  # Include extended meteorology\n",
    ")\n",
    "\n",
    "print(\"Configuration parameters:\")\n",
    "for key, value in config.__dict__.items():\n",
    "    if not key.startswith('_'):\n",
    "        print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Data Analysis with pandas\n",
    "\n",
    "The output DataFrames can be analyzed with pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example analysis: Group by run and compute statistics\n",
    "trajectory_stats = trajectory.groupby('run').agg({\n",
    "    'lat': ['mean', 'min', 'max'],\n",
    "    'lon': ['mean', 'min', 'max'],\n",
    "    'height': ['mean', 'min', 'max'],\n",
    "    'pressure': ['mean', 'min', 'max']\n",
    "}).round(2)\n",
    "\n",
    "trajectory_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter trajectories above certain height\n",
    "high_altitude = trajectory[trajectory['height'] > 500]\n",
    "print(f\"Points above 500m: {len(high_altitude)} ({len(high_altitude)/len(trajectory)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Visualization with Matplotlib\n",
    "\n",
    "Create static plots for publications:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Plot 1: Trajectory paths\n",
    "ax = axes[0]\n",
    "for run_id in trajectory['run'].unique():\n",
    "    run_data = trajectory[trajectory['run'] == run_id]\n",
    "    ax.plot(run_data['lon'], run_data['lat'], 'o-', markersize=3, \n",
    "            label=f'Run {run_id}', alpha=0.7)\n",
    "\n",
    "ax.scatter(trajectory['lon'].iloc[0], trajectory['lat'].iloc[0], \n",
    "           c='red', s=100, marker='*', zorder=10, label='Start')\n",
    "ax.set_xlabel('Longitude')\n",
    "ax.set_ylabel('Latitude')\n",
    "ax.set_title('Trajectory Paths')\n",
    "ax.legend(loc='best', fontsize=8)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Height profile\n",
    "ax = axes[1]\n",
    "for run_id in trajectory['run'].unique():\n",
    "    run_data = trajectory[trajectory['run'] == run_id]\n",
    "    ax.plot(run_data['hour_along'], run_data['height'], 'o-', \n",
    "            markersize=3, label=f'Run {run_id}', alpha=0.7)\n",
    "\n",
    "ax.set_xlabel('Hours Along Trajectory')\n",
    "ax.set_ylabel('Height (m)')\n",
    "ax.set_title('Height Profile')\n",
    "ax.legend(loc='best', fontsize=8)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('trajectory_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This tutorial covered:\n",
    "\n",
    "1. **Installation** - `pip install hysplit` or `pip install \"hysplit[all]\"`\n",
    "2. **Trajectory modeling** - `hysplit_trajectory()` or `create_trajectory_model()`\n",
    "3. **Dispersion modeling** - `create_dispersion_model()` with `add_source()`\n",
    "4. **Cluster workflows** - `download_met_data()` + `run_trajectory_offline()`\n",
    "5. **Batch processing** - `run_batch_trajectories()` with parallel workers\n",
    "\n",
    "For more information:\n",
    "- [GitHub Repository](https://github.com/quishpi/hysplit)\n",
    "- [HYSPLIT Documentation](https://www.ready.noaa.gov/HYSPLIT.php)\n",
    "- [Original R splitr Package](https://github.com/rich-iannone/splitr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
